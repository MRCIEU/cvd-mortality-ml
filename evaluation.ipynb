{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluating ES1 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_sklearn(clf, train_df, test_df, s):\n",
    "    # split out features from outcome\n",
    "    \n",
    "    ## train\n",
    "    x_train = train_df.drop('STATUS_DISCHARGE', axis=1)\n",
    "    y_train = train_df['STATUS_DISCHARGE']\n",
    "    \n",
    "    ## test\n",
    "    x_test = test_df.drop('STATUS_DISCHARGE', axis=1)\n",
    "    y_test = test_df['STATUS_DISCHARGE']\n",
    "    \n",
    "    # train model\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # calculate probabilities for test data\n",
    "    y = clf.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    # check for missing rows\n",
    "    assert len(y) == len(x_test)\n",
    "    \n",
    "    # set row index\n",
    "    y = pd.DataFrame(y, index=x_test.index, columns=[s])\n",
    "\n",
    "    # check for missing rows\n",
    "    assert x_test.shape[0] == y.shape[0]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cv_sklearn(clf, train):   \n",
    "    # split out features from outcome\n",
    "    \n",
    "    ## train\n",
    "    x_train = train.drop('STATUS_DISCHARGE', axis=1)\n",
    "    y_train = train['STATUS_DISCHARGE']\n",
    "    \n",
    "    # train model using k=5 CV\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc', n_jobs=2)\n",
    "    \n",
    "    print(\"ROC AUC: avg {}, sd {}\".format(np.round(np.mean(scores), 3), np.round(np.std(scores), 3)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_grid_search(params, train, numeric_features, means, stds):\n",
    "    scores = []\n",
    "    # iterate over parameters\n",
    "    for hp in params:\n",
    "        print(\"testing model: {}\".format(hp))\n",
    "    \n",
    "        # define model\n",
    "        model = tf.keras.Sequential()\n",
    "    \n",
    "        # add hidden layer\n",
    "        for layer in hp:\n",
    "            model.add(tf.keras.layers.Dense(layer, activation='relu'))\n",
    "    \n",
    "        # add output layer\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "        # train and test model\n",
    "        scores.append(fit_cv_tf(model, train, numeric_features, means, stds))\n",
    "    \n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cv_tf(model, train, numeric_features, means, stds):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "    ## split data into kfolds and train model\n",
    "    kf = KFold(n_splits=5, random_state=0)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        ## apply standardisation to df & make tf dataset\n",
    "        x_train, y_train = process_data(train.iloc[train_index], numeric_features, means, stds)\n",
    "        x_test, y_test = process_data(train.iloc[test_index], numeric_features, means, stds)\n",
    "    \n",
    "        ## fit\n",
    "        model.fit(x_train, y_train, epochs=15, verbose=0)\n",
    "    \n",
    "        # predict test probabilities\n",
    "        y_test_pred = model.predict(x_test)\n",
    "    \n",
    "        # calculate roc auc metric\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "        scores.append(auc(fpr, tpr))\n",
    "\n",
    "    print(\"ROC AUC: avg {}, sd {}\".format(np.round(np.mean(scores), 3), np.round(np.std(scores), 3)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, numeric_features, means, stds):\n",
    "    \n",
    "    # convert bool to int\n",
    "    bool_columns = df.select_dtypes(['bool']).columns\n",
    "    df[bool_columns] = df[bool_columns].astype('int')\n",
    "    \n",
    "    # normalise continuous variables\n",
    "    for i, f in enumerate(numeric_features):\n",
    "        df[f] = (df[f] - means[i]) / stds[i]\n",
    "    \n",
    "    # split x and y\n",
    "    target = df.pop('STATUS_DISCHARGE')\n",
    "    \n",
    "    return df.values, target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data (see feature selection notebook) from csv\n",
    "train = pd.read_csv('train.esi.features.17.02.20.csv', index_col=0)\n",
    "test = pd.read_csv('test.esi.features.17.02.20.csv', index_col=0)\n",
    "\n",
    "# load ES1 & 2 scores\n",
    "esi_prob = pd.read_csv('test.esi.score.17.02.20.csv', index_col=0)\n",
    "esii_prob = pd.read_csv('test.esii.score.17.02.20.csv', index_col=0)\n",
    "probs = pd.merge(esi_prob, esii_prob, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# merge outcome on probs\n",
    "probs = pd.merge(probs, test['STATUS_DISCHARGE'], how='left', left_index=True, right_index=True)\n",
    "\n",
    "# convert bool to int\n",
    "bool_columns = train.select_dtypes(['bool']).columns\n",
    "train[bool_columns] = train[bool_columns].astype('int')\n",
    "bool_columns = test.select_dtypes(['bool']).columns\n",
    "test[bool_columns] = test[bool_columns].astype('int')\n",
    "\n",
    "# get mean and SD for **training** dataset to standardise variables\n",
    "numeric_features = ['Age (continuous)']\n",
    "desc = train[numeric_features].describe()\n",
    "means = np.array(desc.T['mean'])\n",
    "stds = np.array(desc.T['std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.822, sd 0.016\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=50000)\n",
    "scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0218 12:18:59.212293  2700 deprecation.py:506] From C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model: [18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "W0218 12:18:59.660533  2700 deprecation.py:323] From C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.826, sd 0.014\n",
      "testing model: [36]\n",
      "ROC AUC: avg 0.826, sd 0.008\n",
      "testing model: [54]\n",
      "ROC AUC: avg 0.828, sd 0.005\n",
      "testing model: [72]\n",
      "ROC AUC: avg 0.828, sd 0.008\n",
      "testing model: [90]\n",
      "ROC AUC: avg 0.835, sd 0.008\n",
      "testing model: [108]\n",
      "ROC AUC: avg 0.83, sd 0.006\n",
      "testing model: [126]\n",
      "ROC AUC: avg 0.833, sd 0.002\n",
      "testing model: [144]\n",
      "ROC AUC: avg 0.835, sd 0.007\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "params = [\n",
    "    [18],\n",
    "    [36],\n",
    "    [54],\n",
    "    [72],\n",
    "    [90],\n",
    "    [108],\n",
    "    [126],\n",
    "    [144]\n",
    "]\n",
    "scores = tf_grid_search(params, train, numeric_features, means, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model: [18, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.825, sd 0.016\n",
      "testing model: [36, 18]\n",
      "ROC AUC: avg 0.831, sd 0.005\n",
      "testing model: [54, 18]\n",
      "ROC AUC: avg 0.834, sd 0.005\n",
      "testing model: [72, 18]\n",
      "ROC AUC: avg 0.834, sd 0.005\n",
      "testing model: [90, 18]\n",
      "ROC AUC: avg 0.823, sd 0.012\n",
      "testing model: [108, 18]\n",
      "ROC AUC: avg 0.825, sd 0.011\n",
      "testing model: [126, 18]\n",
      "ROC AUC: avg 0.829, sd 0.009\n",
      "testing model: [144, 18]\n",
      "ROC AUC: avg 0.834, sd 0.009\n",
      "testing model: [72, 36]\n",
      "ROC AUC: avg 0.829, sd 0.008\n",
      "testing model: [72, 54]\n",
      "ROC AUC: avg 0.834, sd 0.009\n",
      "testing model: [72, 72]\n",
      "ROC AUC: avg 0.836, sd 0.011\n",
      "testing model: [72, 90]\n",
      "ROC AUC: avg 0.839, sd 0.009\n",
      "testing model: [72, 108]\n",
      "ROC AUC: avg 0.828, sd 0.008\n",
      "testing model: [72, 126]\n",
      "ROC AUC: avg 0.834, sd 0.02\n",
      "testing model: [72, 144]\n",
      "ROC AUC: avg 0.822, sd 0.021\n",
      "testing model: [90, 36]\n",
      "ROC AUC: avg 0.842, sd 0.008\n",
      "testing model: [90, 54]\n",
      "ROC AUC: avg 0.832, sd 0.017\n",
      "testing model: [90, 72]\n",
      "ROC AUC: avg 0.834, sd 0.006\n",
      "testing model: [90, 90]\n",
      "ROC AUC: avg 0.834, sd 0.014\n",
      "testing model: [90, 108]\n",
      "ROC AUC: avg 0.838, sd 0.01\n",
      "testing model: [90, 126]\n",
      "ROC AUC: avg 0.832, sd 0.014\n",
      "testing model: [90, 144]\n",
      "ROC AUC: avg 0.836, sd 0.014\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "params = [\n",
    "    [18, 18],\n",
    "    [36, 18],\n",
    "    [54, 18],\n",
    "    [72, 18],\n",
    "    [90, 18],\n",
    "    [108, 18],\n",
    "    [126, 18],\n",
    "    [144, 18],\n",
    "    [72, 36],\n",
    "    [72, 54],\n",
    "    [72, 72],\n",
    "    [72, 90],\n",
    "    [72, 108],\n",
    "    [72, 126],\n",
    "    [72, 144],\n",
    "    [90, 36],\n",
    "    [90, 54],\n",
    "    [90, 72], # best\n",
    "    [90, 90],\n",
    "    [90, 108],\n",
    "    [90, 126],\n",
    "    [90, 144]\n",
    "]\n",
    "scores = tf_grid_search(params, train, numeric_features, means, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model: [90, 36, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.823, sd 0.01\n",
      "testing model: [90, 36, 18]\n",
      "ROC AUC: avg 0.832, sd 0.012\n",
      "testing model: [90, 36, 27]\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "params = [\n",
    "    [90, 36, 9],\n",
    "    [90, 36, 18],\n",
    "    [90, 36, 27],\n",
    "    [90, 36, 36],\n",
    "    [90, 18, 18],\n",
    "    [90, 27, 18],\n",
    "]\n",
    "scores = tf_grid_search(params, train, numeric_features, means, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.656, sd 0.027\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.725, sd 0.021\n",
      "ROC AUC: avg 0.731, sd 0.024\n",
      "ROC AUC: avg 0.735, sd 0.023\n",
      "ROC AUC: avg 0.738, sd 0.024\n",
      "ROC AUC: avg 0.741, sd 0.023\n",
      "ROC AUC: avg 0.743, sd 0.022\n",
      "ROC AUC: avg 0.745, sd 0.024\n"
     ]
    }
   ],
   "source": [
    "for p in [200, 300, 400, 500, 600, 700, 800]:\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=p)\n",
    "    scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [1, 5, 10, 20, 50]:\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=p)\n",
    "    scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min samples split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [2, 5, 10, 20]:\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=10, min_samples_split=p)\n",
    "    scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min samples leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [1, 2, 5, 10, 20, 30]:\n",
    "    clf = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=10, min_samples_split=5, min_samples_leaf=p)\n",
    "    scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: avg 0.779, sd 0.024\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "scores = fit_cv_sklearn(clf, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0219 13:05:26.099060  5328 deprecation.py:506] From C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0219 13:05:26.496416  5328 deprecation.py:323] From C:\\Users\\LyonMat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=50000)\n",
    "prob = get_prob_sklearn(clf, train, test, \"LR\")\n",
    "probs = pd.merge(probs, prob, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# RF\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=700, max_depth=10, min_samples_split=5, min_samples_leaf=20)\n",
    "prob = get_prob_sklearn(clf, train, test, \"RF\")\n",
    "probs = pd.merge(probs, prob, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# NB\n",
    "clf = GaussianNB()\n",
    "prob = get_prob_sklearn(clf, train, test, \"NB\")\n",
    "probs = pd.merge(probs, prob, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# NN\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense('90', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense('36', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "x_train, y_train = process_data(train, numeric_features, means, stds)\n",
    "x_test, y_test = process_data(test, numeric_features, means, stds)\n",
    "model.fit(x_train, y_train, epochs=15, verbose=0)\n",
    "y = model.predict(x_test)\n",
    "y = pd.DataFrame(y, index=test.index, columns=['NN'])\n",
    "probs = pd.merge(probs, y, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# write out final probabilities\n",
    "probs.to_csv(\"probs.19.02.20.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
